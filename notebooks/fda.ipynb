{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c7c812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size: 15\n",
      "Brands covered:\n",
      "['اکتانیت   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 250 [iU]  [iU]']\n",
      "['COAGULATION FACTOR VIII (HUMAN PLASMA DERIVED) INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION PARENTERAL 250 [iU]']\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataframe size: 1066\n",
      "Brands covered:\n",
      "['آیمافیکس   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 500 [iU]  [iU]'\n",
      " 'هموناین   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 500 [iU]  [iU]'\n",
      " 'آیمافیکس500   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 500 [iU]  [iU]']\n",
      "['FACTOR IX INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION PARENTERAL 500 [iU]']\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "Dataframe size: 1272\n",
      "Brands covered:\n",
      "['اموکلات   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 500 [iU]  [iU]'\n",
      " 'هماکتین   پودر لئوفیلیزه برای تهیه محلول تزریقی پرنترال 500 [iU]  [iU]']\n",
      "['COAGULATION FACTOR VIII (HUMAN PLASMA DERIVED) INJECTION, POWDER, LYOPHILIZED, FOR SOLUTION PARENTERAL 500 [iU]']\n",
      "----------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT: Path = Path(os.getcwd()).resolve().parents[0]\n",
    "\n",
    "parts = [1, 2, 3]\n",
    "\n",
    "\n",
    "def read_file(part: int | str, root: Path = PROJECT_ROOT):\n",
    "    path: Path = root / \"data\" / \"raw\" / f\"private-fda-part-{str(part)}.xlsx\"\n",
    "    if path.exists():\n",
    "        return pd.read_excel(path)\n",
    "    else:\n",
    "        raise ValueError(\"File not found\")\n",
    "\n",
    "\n",
    "column_name_translation = {\n",
    "    \"جی ال ان توزیع کننده\": \"distributor_gln\",\n",
    "    \"نام توزیع کننده\": \"distributor_name\",\n",
    "    \"جی ال ان داروخانه\": \"pharmacy_gln\",\n",
    "    \"نام داروخانه\": \"pharmacy_name\",\n",
    "    \"تلفن ثابت داروخانه \": \"pharmacy_phone\",\n",
    "    \"شماره موبایل موسس داروخانه\": \"pharmacy_founder_mobile\",\n",
    "    \"آدرس  داروخانه\": \"pharmacy_address\",\n",
    "    \"نوع فرآورده\": \"product_type\",\n",
    "    \"کد فرآورده\": \"product_code\",\n",
    "    \"نام برند\": \"brand_name\",\n",
    "    \"کد ژنریک\": \"generic_code\",\n",
    "    \"نام ژنریک\": \"generic_name\",\n",
    "    \"سری ساخت\": \"batch_number\",\n",
    "    \"تاریخ رویداد\": \"event_date\",\n",
    "    \"نام مالک فرآورده\": \"product_owner_name\",\n",
    "    \"نام تامین کننده\": \"supplier_name\",\n",
    "    \"تعداد در بسته\": \"units_per_package\",\n",
    "    \"تعداد بسته ارسال شده\": \"packages_sent\",\n",
    "    \"مجموع ارسال شده\": \"total_units_sent\",\n",
    "    \"ارزش ریالی\": \"monetary_value\",\n",
    "    \"استان\": \"province\",\n",
    "    \"شهرستان\": \"county\",\n",
    "    \"شهر\": \"city\",\n",
    "    \"دانشگاه\": \"university\",\n",
    "}\n",
    "\n",
    "columns_to_truncate = [\n",
    "    \"city\",\n",
    "    \"county\",\n",
    "    \"province\",\n",
    "    \"university\",\n",
    "    \"pharmacy_address\",\n",
    "    \"distributor_gln\",\n",
    "    \"event_date\",\n",
    "    \"product_type\",\n",
    "    \"pharmacy_founder_mobile\",\n",
    "    \"pharmacy_phone\",\n",
    "    \"pharmacy_name\",\n",
    "    \"batch_number\",\n",
    "    \"pharmacy_gln\",\n",
    "    \"distributor_name\",\n",
    "]\n",
    "dfs_farsi = [read_file(part) for part in parts]\n",
    "dfs_english = [df.rename(columns=column_name_translation) for df in dfs_farsi]\n",
    "dfs_truncated = [df.drop(columns=columns_to_truncate) for df in dfs_english]\n",
    "for df_uniques in dfs_truncated:\n",
    "    print(f\"Dataframe size: {df_uniques['generic_code'].count()}\")  # 15, 1066, 1272\n",
    "    print(\"Brands covered:\")\n",
    "    print(df_uniques[\"brand_name\"].unique())\n",
    "    print(df_uniques[\"generic_name\"].unique())\n",
    "    print(\"-\" * 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073b3bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Dataframe\n",
      "Total iU sent: 164000\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "Second Dataframe\n",
      "Factor IX ignored\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "Third Dataframe\n",
      "Total iU sent: 89345500\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "Overall iU consumption: 89509500\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "pattern = r\"(\\d+)\\s*\\[iU\\]\"\n",
    "dfs_truncated_dict = {\n",
    "    \"First\": dfs_truncated[0],\n",
    "    \"Second\": dfs_truncated[1],\n",
    "    \"Third\": dfs_truncated[2],\n",
    "}\n",
    "overall_unit_sent = []\n",
    "for name, df_uniques in dfs_truncated_dict.items():\n",
    "    print(f\"{name} Dataframe\")\n",
    "    if name == \"Second\":\n",
    "        print(\"Factor IX ignored\")\n",
    "        print(\"-\" * 124)\n",
    "        continue\n",
    "    generics = df_uniques[\"generic_name\"].unique()\n",
    "    for generic in generics:\n",
    "        match = re.search(pattern, generic)\n",
    "        if match:\n",
    "            dosage = int(match.group(1))\n",
    "            total_unit = df_uniques[\"total_units_sent\"].sum() * dosage\n",
    "            overall_unit_sent.append(int(total_unit))\n",
    "            print(f\"Total iU sent: {total_unit}\")\n",
    "        else:\n",
    "            print(\"No dosage found\")\n",
    "        print(\"-\" * 124)\n",
    "print(f\"Overall iU consumption: {np.array(overall_unit_sent).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7183d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Loading Full FDA Statistics 2023\n",
    "AMARNAMEH_PATH = PROJECT_ROOT / \"data\" / \"raw\" / \"private-statistics-2023.xlsx\"\n",
    "df_cumulative = pd.read_excel(AMARNAMEH_PATH, sheet_name=\"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b23848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Full FDA Statistics 2023\n",
    "column_name_translation = {\n",
    "    \"نام شرکت پخش\": \"supplier\",\n",
    "    \"نام صاحب برند\": \"brand_owner\",\n",
    "    \"نام شرکت تامین کننده\": \"supplier_company_name\",\n",
    "    \"نام شرکت تولید کننده\": \"manufacturer_company_name\",\n",
    "    \"کد IRC محصول\": \"irc_code\",\n",
    "    \"نام لاتین برند\": \"brand_latin_name\",\n",
    "    \"نام برند\": \"brand_name\",\n",
    "    \"نام لاتین فهرست\": \"index_latin_name\",\n",
    "    \"کد ژنریک\": \"generic_code\",\n",
    "    \"نام ژنریک\": \"generic_name\",\n",
    "    \"تعداد فروش (بسته)\": \"count_of_package_sold\",\n",
    "    \"تعداد در بسته\": \"count_in_package\",\n",
    "    \"فروش عددی\": \"sale_count\",\n",
    "    \"فروش ریالی ( مبتنی بر قیمت مصرف کننده)\": \"sale_amount\",\n",
    "    \"OTC\": \"otc\",\n",
    "    \"بیولوژیک\": \"biologic\",\n",
    "    \"تحت لیسانس\": \"licensed\",\n",
    "    \"کد ATC\": \"atc_code\",\n",
    "    \"کشور تولید کننده\": \"manufacturer_country\",\n",
    "    \"ثابت/فهرست\": \"constant\",\n",
    "    \"تولیدی/وارداتی\": \"imported_manufactured\",\n",
    "    \"ثبتی/فوریتی\": \"emergency_registered\",\n",
    "}\n",
    "df_cumulative = df_cumulative.rename(columns=column_name_translation)\n",
    "df_uniques = df_cumulative[\n",
    "    [\"index_latin_name\", \"brand_latin_name\", \"generic_name\", \"generic_code\", \"irc_code\"]\n",
    "]\n",
    "\n",
    "df_uniques = df_uniques[df_uniques[\"generic_name\"].str.contains(\"factor\", case=False)]\n",
    "df_uniques = df_uniques[\n",
    "    ~df_uniques[\"generic_name\"].str.contains(\"viia\", case=False)\n",
    "    & ~df_uniques[\"generic_name\"].str.contains(\"ix\", case=False)\n",
    "    & ~df_uniques[\"generic_name\"].str.contains(\"xiii\", case=False)\n",
    "]\n",
    "df_uniques = df_uniques.drop_duplicates(subset=\"brand_latin_name\")\n",
    "\n",
    "df = df_cumulative[\n",
    "    [\n",
    "        \"generic_name\",\n",
    "        \"brand_latin_name\",\n",
    "        \"count_of_package_sold\",\n",
    "        \"sale_count\",\n",
    "        \"sale_amount\",\n",
    "    ]\n",
    "]\n",
    "df = df[df[\"generic_name\"].str.contains(\"factor viii\", case=False)]\n",
    "agg_dict = {\n",
    "    \"generic_name\": \"first\",\n",
    "    \"brand_latin_name\": \"first\",\n",
    "    \"count_of_package_sold\": \"sum\",\n",
    "    \"sale_count\": \"sum\",\n",
    "    \"sale_amount\": \"sum\",\n",
    "}\n",
    "df = df.groupby(by=\"brand_latin_name\", as_index=False).agg(agg_dict)\n",
    "df[\"brand_latin_name\"] = (\n",
    "    df[\"brand_latin_name\"].str.extract(r\"^([A-Z\\s]+?)\\s{2,}\")[0].str.strip()\n",
    ")\n",
    "df[\"dosage\"] = df[\"generic_name\"].str.extract(r\"(\\d+)\\s*\")[0].str.strip()\n",
    "df[\"dosage\"] = df[\"dosage\"].astype(np.int64)\n",
    "\n",
    "OUTPUT_PATH: Path = PROJECT_ROOT / \"data\" / \"processed\" / \"factor_viii_2023.xlsx\"\n",
    "if OUTPUT_PATH.exists():\n",
    "    override = input(\"File already exists, should override? (Y/N)\")\n",
    "    if override.lower() == \"y\":\n",
    "        with pd.ExcelWriter(OUTPUT_PATH) as writer:\n",
    "            print(f\"Storing results at: {OUTPUT_PATH}\")\n",
    "            df_uniques.to_excel(writer, sheet_name=\"dataset\", index=False)\n",
    "            df.to_excel(writer, sheet_name=\"prices\", index=False)\n",
    "    else:\n",
    "        print(\"Ignored\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd3e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing results at: /home/mohammad/projects/Thesis/hemophilia/data/processed/factor_viii_2024.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cleaning 2024 Summary statistics\n",
    "df = pd.read_excel(\n",
    "    io=PROJECT_ROOT / \"data\" / \"raw\" / \"fda-statistics-summary-2024.xlsx\"\n",
    ").rename(columns={\"فروش عددی 1403\": \"sale_count\"})\n",
    "df[\"dosage\"] = df[\"generic_name\"].str.extract(r\"(\\d+)\\s*\")[0].str.strip()\n",
    "df[\"dosage\"] = df[\"dosage\"].astype(np.int64)\n",
    "\n",
    "OUTPUT_PATH: Path = PROJECT_ROOT / \"data\" / \"processed\" / \"factor_viii_2024.xlsx\"\n",
    "if OUTPUT_PATH.exists():\n",
    "    override = input(\"File already exists, should override? (Y/N)\")\n",
    "    if override.lower() == \"y\":\n",
    "        with pd.ExcelWriter(OUTPUT_PATH) as writer:\n",
    "            print(f\"Storing results at: {OUTPUT_PATH}\")\n",
    "            df.to_excel(writer, sheet_name=\"dataset\", index=False)\n",
    "    else:\n",
    "        print(\"Ignored\")\n",
    "else:\n",
    "    with pd.ExcelWriter(OUTPUT_PATH) as writer:\n",
    "        print(f\"Storing results at: {OUTPUT_PATH}\")\n",
    "        df.to_excel(writer, sheet_name=\"dataset\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
